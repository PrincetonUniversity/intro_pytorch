{
  "cells": [
{
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PrincetonUniversity/intro_pytorch/blob/main/01_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-wdordsd3I-8"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIYHpb0F3I-_"
      },
      "source": [
        "# Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
        "In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model’s parameters.\n",
        "\n",
        "Tensors are similar to [NumPy’s](https://numpy.org/) ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and\n",
        "NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see `bridge-to-np-label`). Tensors\n",
        "are also optimized for automatic differentiation (we'll see more about that later in the [Autograd](autogradqs_tutorial.html)_\n",
        "section). If you’re familiar with ndarrays, you’ll be right at home with the Tensor API. If not, follow along!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "viwKcOaa3I_B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeOPJdcu3I_C"
      },
      "source": [
        "## Initializing a Tensor\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BDNJQoPG3I_C"
      },
      "outputs": [],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWlgIM0T3I_C"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see `bridge-to-np-label`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w8SkReDL3I_D"
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpiNNgks3I_D"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YP-PTEWu3I_D",
        "outputId": "b6030aa8-1105-406e-8bde-a596cfa3c8eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.0235, 0.6557],\n",
            "        [0.8303, 0.3682]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmgzF_QL3I_E"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G_NeCSMi3I_E",
        "outputId": "68e8bdef-dd88-41fe-f3cb-591a8ebe5801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.4298, 0.9054, 0.1801],\n",
            "        [0.7626, 0.0572, 0.7075]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lohdIXPh3I_E"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC7D_sNr3I_E"
      },
      "source": [
        "## Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ag18ejRL3I_F",
        "outputId": "a6be1ccb-271e-41a3-e597-69a13a445a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at all the methods and data associated with a Torch tensor:"
      ],
      "metadata": {
        "id": "8dJQvuXLQ5u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tensor)"
      ],
      "metadata": {
        "id": "kjsGR6L2Q0Op",
        "outputId": "334824d5-58d8-4b27-997c-f52fb645923c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['H',\n",
              " 'T',\n",
              " '__abs__',\n",
              " '__add__',\n",
              " '__and__',\n",
              " '__array__',\n",
              " '__array_priority__',\n",
              " '__array_wrap__',\n",
              " '__bool__',\n",
              " '__class__',\n",
              " '__complex__',\n",
              " '__contains__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__div__',\n",
              " '__dlpack__',\n",
              " '__dlpack_device__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__float__',\n",
              " '__floordiv__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__iadd__',\n",
              " '__iand__',\n",
              " '__idiv__',\n",
              " '__ifloordiv__',\n",
              " '__ilshift__',\n",
              " '__imod__',\n",
              " '__imul__',\n",
              " '__index__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__int__',\n",
              " '__invert__',\n",
              " '__ior__',\n",
              " '__ipow__',\n",
              " '__irshift__',\n",
              " '__isub__',\n",
              " '__iter__',\n",
              " '__itruediv__',\n",
              " '__ixor__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__long__',\n",
              " '__lshift__',\n",
              " '__lt__',\n",
              " '__matmul__',\n",
              " '__mod__',\n",
              " '__module__',\n",
              " '__mul__',\n",
              " '__ne__',\n",
              " '__neg__',\n",
              " '__new__',\n",
              " '__nonzero__',\n",
              " '__or__',\n",
              " '__pos__',\n",
              " '__pow__',\n",
              " '__radd__',\n",
              " '__rand__',\n",
              " '__rdiv__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__rfloordiv__',\n",
              " '__rlshift__',\n",
              " '__rmatmul__',\n",
              " '__rmod__',\n",
              " '__rmul__',\n",
              " '__ror__',\n",
              " '__rpow__',\n",
              " '__rrshift__',\n",
              " '__rshift__',\n",
              " '__rsub__',\n",
              " '__rtruediv__',\n",
              " '__rxor__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__sub__',\n",
              " '__subclasshook__',\n",
              " '__torch_dispatch__',\n",
              " '__torch_function__',\n",
              " '__truediv__',\n",
              " '__weakref__',\n",
              " '__xor__',\n",
              " '_addmm_activation',\n",
              " '_autocast_to_full_precision',\n",
              " '_autocast_to_reduced_precision',\n",
              " '_backward_hooks',\n",
              " '_base',\n",
              " '_cdata',\n",
              " '_coalesced_',\n",
              " '_conj',\n",
              " '_conj_physical',\n",
              " '_dimI',\n",
              " '_dimV',\n",
              " '_fix_weakref',\n",
              " '_grad',\n",
              " '_grad_fn',\n",
              " '_has_symbolic_sizes_strides',\n",
              " '_indices',\n",
              " '_is_all_true',\n",
              " '_is_any_true',\n",
              " '_is_view',\n",
              " '_is_zerotensor',\n",
              " '_make_subclass',\n",
              " '_make_wrapper_subclass',\n",
              " '_neg_view',\n",
              " '_nested_tensor_size',\n",
              " '_nested_tensor_storage_offsets',\n",
              " '_nested_tensor_strides',\n",
              " '_nnz',\n",
              " '_post_accumulate_grad_hooks',\n",
              " '_python_dispatch',\n",
              " '_reduce_ex_internal',\n",
              " '_sparse_mask_projection',\n",
              " '_to_dense',\n",
              " '_to_sparse',\n",
              " '_to_sparse_bsc',\n",
              " '_to_sparse_bsr',\n",
              " '_to_sparse_csc',\n",
              " '_to_sparse_csr',\n",
              " '_typed_storage',\n",
              " '_update_names',\n",
              " '_values',\n",
              " '_version',\n",
              " '_view_func',\n",
              " 'abs',\n",
              " 'abs_',\n",
              " 'absolute',\n",
              " 'absolute_',\n",
              " 'acos',\n",
              " 'acos_',\n",
              " 'acosh',\n",
              " 'acosh_',\n",
              " 'add',\n",
              " 'add_',\n",
              " 'addbmm',\n",
              " 'addbmm_',\n",
              " 'addcdiv',\n",
              " 'addcdiv_',\n",
              " 'addcmul',\n",
              " 'addcmul_',\n",
              " 'addmm',\n",
              " 'addmm_',\n",
              " 'addmv',\n",
              " 'addmv_',\n",
              " 'addr',\n",
              " 'addr_',\n",
              " 'adjoint',\n",
              " 'align_as',\n",
              " 'align_to',\n",
              " 'all',\n",
              " 'allclose',\n",
              " 'amax',\n",
              " 'amin',\n",
              " 'aminmax',\n",
              " 'angle',\n",
              " 'any',\n",
              " 'apply_',\n",
              " 'arccos',\n",
              " 'arccos_',\n",
              " 'arccosh',\n",
              " 'arccosh_',\n",
              " 'arcsin',\n",
              " 'arcsin_',\n",
              " 'arcsinh',\n",
              " 'arcsinh_',\n",
              " 'arctan',\n",
              " 'arctan2',\n",
              " 'arctan2_',\n",
              " 'arctan_',\n",
              " 'arctanh',\n",
              " 'arctanh_',\n",
              " 'argmax',\n",
              " 'argmin',\n",
              " 'argsort',\n",
              " 'argwhere',\n",
              " 'as_strided',\n",
              " 'as_strided_',\n",
              " 'as_strided_scatter',\n",
              " 'as_subclass',\n",
              " 'asin',\n",
              " 'asin_',\n",
              " 'asinh',\n",
              " 'asinh_',\n",
              " 'atan',\n",
              " 'atan2',\n",
              " 'atan2_',\n",
              " 'atan_',\n",
              " 'atanh',\n",
              " 'atanh_',\n",
              " 'backward',\n",
              " 'baddbmm',\n",
              " 'baddbmm_',\n",
              " 'bernoulli',\n",
              " 'bernoulli_',\n",
              " 'bfloat16',\n",
              " 'bincount',\n",
              " 'bitwise_and',\n",
              " 'bitwise_and_',\n",
              " 'bitwise_left_shift',\n",
              " 'bitwise_left_shift_',\n",
              " 'bitwise_not',\n",
              " 'bitwise_not_',\n",
              " 'bitwise_or',\n",
              " 'bitwise_or_',\n",
              " 'bitwise_right_shift',\n",
              " 'bitwise_right_shift_',\n",
              " 'bitwise_xor',\n",
              " 'bitwise_xor_',\n",
              " 'bmm',\n",
              " 'bool',\n",
              " 'broadcast_to',\n",
              " 'byte',\n",
              " 'cauchy_',\n",
              " 'ccol_indices',\n",
              " 'cdouble',\n",
              " 'ceil',\n",
              " 'ceil_',\n",
              " 'cfloat',\n",
              " 'chalf',\n",
              " 'char',\n",
              " 'cholesky',\n",
              " 'cholesky_inverse',\n",
              " 'cholesky_solve',\n",
              " 'chunk',\n",
              " 'clamp',\n",
              " 'clamp_',\n",
              " 'clamp_max',\n",
              " 'clamp_max_',\n",
              " 'clamp_min',\n",
              " 'clamp_min_',\n",
              " 'clip',\n",
              " 'clip_',\n",
              " 'clone',\n",
              " 'coalesce',\n",
              " 'col_indices',\n",
              " 'conj',\n",
              " 'conj_physical',\n",
              " 'conj_physical_',\n",
              " 'contiguous',\n",
              " 'copy_',\n",
              " 'copysign',\n",
              " 'copysign_',\n",
              " 'corrcoef',\n",
              " 'cos',\n",
              " 'cos_',\n",
              " 'cosh',\n",
              " 'cosh_',\n",
              " 'count_nonzero',\n",
              " 'cov',\n",
              " 'cpu',\n",
              " 'cross',\n",
              " 'crow_indices',\n",
              " 'cuda',\n",
              " 'cummax',\n",
              " 'cummin',\n",
              " 'cumprod',\n",
              " 'cumprod_',\n",
              " 'cumsum',\n",
              " 'cumsum_',\n",
              " 'data',\n",
              " 'data_ptr',\n",
              " 'deg2rad',\n",
              " 'deg2rad_',\n",
              " 'dense_dim',\n",
              " 'dequantize',\n",
              " 'det',\n",
              " 'detach',\n",
              " 'detach_',\n",
              " 'device',\n",
              " 'diag',\n",
              " 'diag_embed',\n",
              " 'diagflat',\n",
              " 'diagonal',\n",
              " 'diagonal_scatter',\n",
              " 'diff',\n",
              " 'digamma',\n",
              " 'digamma_',\n",
              " 'dim',\n",
              " 'dim_order',\n",
              " 'dist',\n",
              " 'div',\n",
              " 'div_',\n",
              " 'divide',\n",
              " 'divide_',\n",
              " 'dot',\n",
              " 'double',\n",
              " 'dsplit',\n",
              " 'dtype',\n",
              " 'eig',\n",
              " 'element_size',\n",
              " 'eq',\n",
              " 'eq_',\n",
              " 'equal',\n",
              " 'erf',\n",
              " 'erf_',\n",
              " 'erfc',\n",
              " 'erfc_',\n",
              " 'erfinv',\n",
              " 'erfinv_',\n",
              " 'exp',\n",
              " 'exp2',\n",
              " 'exp2_',\n",
              " 'exp_',\n",
              " 'expand',\n",
              " 'expand_as',\n",
              " 'expm1',\n",
              " 'expm1_',\n",
              " 'exponential_',\n",
              " 'fill_',\n",
              " 'fill_diagonal_',\n",
              " 'fix',\n",
              " 'fix_',\n",
              " 'flatten',\n",
              " 'flip',\n",
              " 'fliplr',\n",
              " 'flipud',\n",
              " 'float',\n",
              " 'float_power',\n",
              " 'float_power_',\n",
              " 'floor',\n",
              " 'floor_',\n",
              " 'floor_divide',\n",
              " 'floor_divide_',\n",
              " 'fmax',\n",
              " 'fmin',\n",
              " 'fmod',\n",
              " 'fmod_',\n",
              " 'frac',\n",
              " 'frac_',\n",
              " 'frexp',\n",
              " 'gather',\n",
              " 'gcd',\n",
              " 'gcd_',\n",
              " 'ge',\n",
              " 'ge_',\n",
              " 'geometric_',\n",
              " 'geqrf',\n",
              " 'ger',\n",
              " 'get_device',\n",
              " 'grad',\n",
              " 'grad_fn',\n",
              " 'greater',\n",
              " 'greater_',\n",
              " 'greater_equal',\n",
              " 'greater_equal_',\n",
              " 'gt',\n",
              " 'gt_',\n",
              " 'half',\n",
              " 'hardshrink',\n",
              " 'has_names',\n",
              " 'heaviside',\n",
              " 'heaviside_',\n",
              " 'histc',\n",
              " 'histogram',\n",
              " 'hsplit',\n",
              " 'hypot',\n",
              " 'hypot_',\n",
              " 'i0',\n",
              " 'i0_',\n",
              " 'igamma',\n",
              " 'igamma_',\n",
              " 'igammac',\n",
              " 'igammac_',\n",
              " 'imag',\n",
              " 'index_add',\n",
              " 'index_add_',\n",
              " 'index_copy',\n",
              " 'index_copy_',\n",
              " 'index_fill',\n",
              " 'index_fill_',\n",
              " 'index_put',\n",
              " 'index_put_',\n",
              " 'index_reduce',\n",
              " 'index_reduce_',\n",
              " 'index_select',\n",
              " 'indices',\n",
              " 'inner',\n",
              " 'int',\n",
              " 'int_repr',\n",
              " 'inverse',\n",
              " 'ipu',\n",
              " 'is_coalesced',\n",
              " 'is_complex',\n",
              " 'is_conj',\n",
              " 'is_contiguous',\n",
              " 'is_cpu',\n",
              " 'is_cuda',\n",
              " 'is_distributed',\n",
              " 'is_floating_point',\n",
              " 'is_inference',\n",
              " 'is_ipu',\n",
              " 'is_leaf',\n",
              " 'is_meta',\n",
              " 'is_mkldnn',\n",
              " 'is_mps',\n",
              " 'is_neg',\n",
              " 'is_nested',\n",
              " 'is_nonzero',\n",
              " 'is_ort',\n",
              " 'is_pinned',\n",
              " 'is_quantized',\n",
              " 'is_same_size',\n",
              " 'is_set_to',\n",
              " 'is_shared',\n",
              " 'is_signed',\n",
              " 'is_sparse',\n",
              " 'is_sparse_csr',\n",
              " 'is_vulkan',\n",
              " 'is_xla',\n",
              " 'is_xpu',\n",
              " 'isclose',\n",
              " 'isfinite',\n",
              " 'isinf',\n",
              " 'isnan',\n",
              " 'isneginf',\n",
              " 'isposinf',\n",
              " 'isreal',\n",
              " 'istft',\n",
              " 'item',\n",
              " 'itemsize',\n",
              " 'kron',\n",
              " 'kthvalue',\n",
              " 'layout',\n",
              " 'lcm',\n",
              " 'lcm_',\n",
              " 'ldexp',\n",
              " 'ldexp_',\n",
              " 'le',\n",
              " 'le_',\n",
              " 'lerp',\n",
              " 'lerp_',\n",
              " 'less',\n",
              " 'less_',\n",
              " 'less_equal',\n",
              " 'less_equal_',\n",
              " 'lgamma',\n",
              " 'lgamma_',\n",
              " 'log',\n",
              " 'log10',\n",
              " 'log10_',\n",
              " 'log1p',\n",
              " 'log1p_',\n",
              " 'log2',\n",
              " 'log2_',\n",
              " 'log_',\n",
              " 'log_normal_',\n",
              " 'log_softmax',\n",
              " 'logaddexp',\n",
              " 'logaddexp2',\n",
              " 'logcumsumexp',\n",
              " 'logdet',\n",
              " 'logical_and',\n",
              " 'logical_and_',\n",
              " 'logical_not',\n",
              " 'logical_not_',\n",
              " 'logical_or',\n",
              " 'logical_or_',\n",
              " 'logical_xor',\n",
              " 'logical_xor_',\n",
              " 'logit',\n",
              " 'logit_',\n",
              " 'logsumexp',\n",
              " 'long',\n",
              " 'lstsq',\n",
              " 'lt',\n",
              " 'lt_',\n",
              " 'lu',\n",
              " 'lu_solve',\n",
              " 'mH',\n",
              " 'mT',\n",
              " 'map2_',\n",
              " 'map_',\n",
              " 'masked_fill',\n",
              " 'masked_fill_',\n",
              " 'masked_scatter',\n",
              " 'masked_scatter_',\n",
              " 'masked_select',\n",
              " 'matmul',\n",
              " 'matrix_exp',\n",
              " 'matrix_power',\n",
              " 'max',\n",
              " 'maximum',\n",
              " 'mean',\n",
              " 'median',\n",
              " 'min',\n",
              " 'minimum',\n",
              " 'mm',\n",
              " 'mode',\n",
              " 'moveaxis',\n",
              " 'movedim',\n",
              " 'msort',\n",
              " 'mul',\n",
              " 'mul_',\n",
              " 'multinomial',\n",
              " 'multiply',\n",
              " 'multiply_',\n",
              " 'mv',\n",
              " 'mvlgamma',\n",
              " 'mvlgamma_',\n",
              " 'name',\n",
              " 'names',\n",
              " 'nan_to_num',\n",
              " 'nan_to_num_',\n",
              " 'nanmean',\n",
              " 'nanmedian',\n",
              " 'nanquantile',\n",
              " 'nansum',\n",
              " 'narrow',\n",
              " 'narrow_copy',\n",
              " 'nbytes',\n",
              " 'ndim',\n",
              " 'ndimension',\n",
              " 'ne',\n",
              " 'ne_',\n",
              " 'neg',\n",
              " 'neg_',\n",
              " 'negative',\n",
              " 'negative_',\n",
              " 'nelement',\n",
              " 'new',\n",
              " 'new_empty',\n",
              " 'new_empty_strided',\n",
              " 'new_full',\n",
              " 'new_ones',\n",
              " 'new_tensor',\n",
              " 'new_zeros',\n",
              " 'nextafter',\n",
              " 'nextafter_',\n",
              " 'nonzero',\n",
              " 'nonzero_static',\n",
              " 'norm',\n",
              " 'normal_',\n",
              " 'not_equal',\n",
              " 'not_equal_',\n",
              " 'numel',\n",
              " 'numpy',\n",
              " 'orgqr',\n",
              " 'ormqr',\n",
              " 'outer',\n",
              " 'output_nr',\n",
              " 'permute',\n",
              " 'pin_memory',\n",
              " 'pinverse',\n",
              " 'polygamma',\n",
              " 'polygamma_',\n",
              " 'positive',\n",
              " 'pow',\n",
              " 'pow_',\n",
              " 'prelu',\n",
              " 'prod',\n",
              " 'put',\n",
              " 'put_',\n",
              " 'q_per_channel_axis',\n",
              " 'q_per_channel_scales',\n",
              " 'q_per_channel_zero_points',\n",
              " 'q_scale',\n",
              " 'q_zero_point',\n",
              " 'qr',\n",
              " 'qscheme',\n",
              " 'quantile',\n",
              " 'rad2deg',\n",
              " 'rad2deg_',\n",
              " 'random_',\n",
              " 'ravel',\n",
              " 'real',\n",
              " 'reciprocal',\n",
              " 'reciprocal_',\n",
              " 'record_stream',\n",
              " 'refine_names',\n",
              " 'register_hook',\n",
              " 'register_post_accumulate_grad_hook',\n",
              " 'reinforce',\n",
              " 'relu',\n",
              " 'relu_',\n",
              " 'remainder',\n",
              " 'remainder_',\n",
              " 'rename',\n",
              " 'rename_',\n",
              " 'renorm',\n",
              " 'renorm_',\n",
              " 'repeat',\n",
              " 'repeat_interleave',\n",
              " 'requires_grad',\n",
              " 'requires_grad_',\n",
              " 'reshape',\n",
              " 'reshape_as',\n",
              " 'resize',\n",
              " 'resize_',\n",
              " 'resize_as',\n",
              " 'resize_as_',\n",
              " 'resize_as_sparse_',\n",
              " 'resolve_conj',\n",
              " 'resolve_neg',\n",
              " 'retain_grad',\n",
              " 'retains_grad',\n",
              " 'roll',\n",
              " 'rot90',\n",
              " 'round',\n",
              " 'round_',\n",
              " 'row_indices',\n",
              " 'rsqrt',\n",
              " 'rsqrt_',\n",
              " 'scatter',\n",
              " 'scatter_',\n",
              " 'scatter_add',\n",
              " 'scatter_add_',\n",
              " 'scatter_reduce',\n",
              " 'scatter_reduce_',\n",
              " 'select',\n",
              " 'select_scatter',\n",
              " 'set_',\n",
              " 'sgn',\n",
              " 'sgn_',\n",
              " 'shape',\n",
              " 'share_memory_',\n",
              " 'short',\n",
              " 'sigmoid',\n",
              " 'sigmoid_',\n",
              " 'sign',\n",
              " 'sign_',\n",
              " 'signbit',\n",
              " 'sin',\n",
              " 'sin_',\n",
              " 'sinc',\n",
              " 'sinc_',\n",
              " 'sinh',\n",
              " 'sinh_',\n",
              " 'size',\n",
              " 'slice_scatter',\n",
              " 'slogdet',\n",
              " 'smm',\n",
              " 'softmax',\n",
              " 'solve',\n",
              " 'sort',\n",
              " 'sparse_dim',\n",
              " 'sparse_mask',\n",
              " 'sparse_resize_',\n",
              " 'sparse_resize_and_clear_',\n",
              " 'split',\n",
              " 'split_with_sizes',\n",
              " 'sqrt',\n",
              " 'sqrt_',\n",
              " 'square',\n",
              " 'square_',\n",
              " 'squeeze',\n",
              " 'squeeze_',\n",
              " 'sspaddmm',\n",
              " 'std',\n",
              " 'stft',\n",
              " 'storage',\n",
              " 'storage_offset',\n",
              " 'storage_type',\n",
              " 'stride',\n",
              " 'sub',\n",
              " 'sub_',\n",
              " 'subtract',\n",
              " 'subtract_',\n",
              " 'sum',\n",
              " 'sum_to_size',\n",
              " 'svd',\n",
              " 'swapaxes',\n",
              " 'swapaxes_',\n",
              " 'swapdims',\n",
              " 'swapdims_',\n",
              " 'symeig',\n",
              " 't',\n",
              " 't_',\n",
              " 'take',\n",
              " 'take_along_dim',\n",
              " 'tan',\n",
              " 'tan_',\n",
              " 'tanh',\n",
              " 'tanh_',\n",
              " 'tensor_split',\n",
              " 'tile',\n",
              " 'to',\n",
              " 'to_dense',\n",
              " 'to_mkldnn',\n",
              " 'to_padded_tensor',\n",
              " 'to_sparse',\n",
              " 'to_sparse_bsc',\n",
              " 'to_sparse_bsr',\n",
              " 'to_sparse_coo',\n",
              " 'to_sparse_csc',\n",
              " 'to_sparse_csr',\n",
              " 'tolist',\n",
              " 'topk',\n",
              " 'trace',\n",
              " 'transpose',\n",
              " 'transpose_',\n",
              " 'triangular_solve',\n",
              " 'tril',\n",
              " 'tril_',\n",
              " 'triu',\n",
              " 'triu_',\n",
              " 'true_divide',\n",
              " 'true_divide_',\n",
              " 'trunc',\n",
              " 'trunc_',\n",
              " 'type',\n",
              " 'type_as',\n",
              " 'unbind',\n",
              " 'unflatten',\n",
              " 'unfold',\n",
              " 'uniform_',\n",
              " 'unique',\n",
              " 'unique_consecutive',\n",
              " 'unsafe_chunk',\n",
              " 'unsafe_split',\n",
              " 'unsafe_split_with_sizes',\n",
              " 'unsqueeze',\n",
              " 'unsqueeze_',\n",
              " 'untyped_storage',\n",
              " 'values',\n",
              " 'var',\n",
              " 'vdot',\n",
              " 'view',\n",
              " 'view_as',\n",
              " 'vsplit',\n",
              " 'where',\n",
              " 'xlogy',\n",
              " 'xlogy_',\n",
              " 'xpu',\n",
              " 'zero_']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPcxNU5x3I_F"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC8w7D2B3I_F"
      },
      "source": [
        "## Operations on Tensors\n",
        "\n",
        "Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n",
        "indexing, slicing), sampling and more are\n",
        "comprehensively described [here](https://pytorch.org/docs/stable/torch.html)_.\n",
        "\n",
        "Each of these operations can be run on the GPU (at typically higher speeds than on a\n",
        "CPU). If you’re using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n",
        "``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n",
        "across devices can be expensive in terms of time and memory!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0Y2QGIEp3I_F"
      },
      "outputs": [],
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30bmo0aD3I_F"
      },
      "source": [
        "Try out some of the operations from the list.\n",
        "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9bRPDQ53I_F"
      },
      "source": [
        "**Standard numpy-like indexing and slicing:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gGopN8NV3I_G",
        "outputId": "56adbd0b-e251-4615-99ba-f569d10d9d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em5CeIfB3I_G"
      },
      "source": [
        "**Joining tensors** You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
        "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)_,\n",
        "another tensor joining operator that is subtly different from ``torch.cat``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m2YE6-YA3I_G",
        "outputId": "90b2c7d1-7949-4c12-f8ae-8b46743c53e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsvCtN1P3I_G"
      },
      "source": [
        "**Arithmetic operations**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fdq7Kpil3I_G",
        "outputId": "cbe79dfc-80e8-49b0-c258-2d38ee008571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji8I10aq3I_G"
      },
      "source": [
        "**Single-element tensors** If you have a one-element tensor, for example by aggregating all\n",
        "values of a tensor into one value, you can convert it to a Python\n",
        "numerical value using ``item()``:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FoHt9ST23I_G",
        "outputId": "1ba0b44c-974f-4d1e-b3af-5082e2b9c494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWFMeXd23I_H"
      },
      "source": [
        "**In-place operations**\n",
        "Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n",
        "For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i88twBnF3I_H",
        "outputId": "215f14cb-9a39-4e17-c8ba-361f69da6d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpEnKZbJ3I_I"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n",
        "     of history. Hence, their use is discouraged.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw-jl7AD3I_I"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HqKlVN_3I_I"
      },
      "source": [
        "\n",
        "## Bridge with NumPy\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
        "locations, and changing one will change\tthe other.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGSeibQp3I_I"
      },
      "source": [
        "### Tensor to NumPy array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NpxuehOb3I_I",
        "outputId": "4c29de8f-ee9e-42ae-ce5f-8b0ee164b1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxVXMUE73I_I"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mPV_ehT63I_I",
        "outputId": "d1982b90-b495-4bb3-a271-5d6b7a48f6e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0_avjQ13I_J"
      },
      "source": [
        "### NumPy array to Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "djV-7rdT3I_J"
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDc9c-pJ3I_J"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "E_rGvV0w3I_J",
        "outputId": "49410874-9bbb-466a-cc00-f01bc5abd6f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
